<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>zszHexo</title>
  
  
  <link href="/zszhexo.github.io/atom.xml" rel="self"/>
  
  <link href="zhuosongz.github.io/zszhexo.github.io/"/>
  <updated>2019-11-06T02:26:04.900Z</updated>
  <id>zhuosongz.github.io/zszhexo.github.io/</id>
  
  <author>
    <name>zsz</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hello World</title>
    <link href="zhuosongz.github.io/zszhexo.github.io/2019/11/06/hello-world/"/>
    <id>zhuosongz.github.io/zszhexo.github.io/2019/11/06/hello-world/</id>
    <published>2019-11-06T02:26:04.900Z</published>
    <updated>2019-11-06T02:26:04.900Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="quick-start">Quick Start</h2><h3 id="create-a-new-post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="run-server">Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="generate-static-files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="deploy-to-remote-sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p><h3 id="texts-with-color">Texts with color</h3><p><font color="#187892" size="number">内容</font></p><h3 id="to-do-list">To do list</h3><ul><li><i class="fa fa-check-square"></i> 已完成</li><li><i class="fa fa-square"></i> 未完成</li></ul><!-- 一共有两种写法，效果看下面 --><div class="note primary"><p><i class="fa fa-check-square"></i> 已完成 <i class="fa fa-check-square"></i> 已完成 <i class="fa fa-check-square"></i> 已完成 <i class="fa fa-check-square"></i> 已完成 <i class="fa fa-check-square"></i> 已完成 <i class="fa fa-square"></i> 未完成 <i class="fa fa-square"></i> 未完成 <i class="fa fa-square"></i> 未完成</p></div><div class="note primary"><p><i class="fa fa-check-square"></i> 已完成 <i class="fa fa-check-square"></i> 已完成 <i class="fa fa-check-square"></i> 已完成 <i class="fa fa-check-square"></i> 已完成 <i class="fa fa-check-square"></i> 已完成 <i class="fa fa-square"></i> 未完成 <i class="fa fa-square"></i> 未完成 <i class="fa fa-square"></i> 未完成</p></div><div class="note default"><p>default</p></div><div class="note primary"><p>primary</p></div><div class="note success"><p>success</p></div><div class="note info"><p>info</p></div><div class="note warning"><p>warning</p></div><div class="note danger"><p>danger</p></div><div class="note danger no-icon"><p>danger no-icon</p></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>研究日志</title>
    <link href="zhuosongz.github.io/zszhexo.github.io/2019/11/06/%E7%A0%94%E7%A9%B6%E6%97%A5%E5%BF%97/"/>
    <id>zhuosongz.github.io/zszhexo.github.io/2019/11/06/研究日志/</id>
    <published>2019-11-06T00:26:14.000Z</published>
    <updated>2019-11-06T11:30:55.473Z</updated>
    
    <content type="html"><![CDATA[<p><span class="math inline">\(\def\I{\mathbf{1}}\)</span></p><ul><li>睡觉时间：12:00</li><li>起床时间：7:40</li><li>到办公室时间：8:25</li></ul><blockquote><p>今天改坐198路公交，会快一些。一不用倒车，二速度也快一些，三来班次也多一些。以后可以考虑坐这一班。</p></blockquote><h2 id="待办事项">待办事项</h2><ul><li><i class="fa fa-check-square"></i> 早起</li><li><i class="fa fa-check-square"></i> 读Adrian的文章 （8:45--9:30）</li><li><i class="fa fa-square"></i> 考虑一个集中不等(用Stein method和Adrian的idea.)(9:40--11:00)</li><li><i class="fa fa-square"></i> 改一改多元文章</li><li><i class="fa fa-square"></i> 待定</li><li><i class="fa fa-square"></i> 待定</li><li><i class="fa fa-square"></i> 待定</li><li><i class="fa fa-square"></i> 待定</li><li><i class="fa fa-square"></i> 待定</li></ul><h2 id="adrians-paper">1. Adrian's paper</h2><p><a href="https://arxiv.org/pdf/1903.09319.pdf" target="_blank" rel="noopener">The paper</a> is written by Louis H. Y. Chen, Larry Goldstein and Adrian Rollin.</p><p>The model is:</p><div class="note success no-icon"><p>Consider the Erdos-Renyi random graph <span class="math inline">\(\mathcal{G}_n\sim \mathrm{ER}(n,m)\)</span> on <span class="math inline">\(n\)</span> vertices, having exactly <span class="math inline">\(m\)</span> edges, distributed uniformly at random. Let <span class="math inline">\(d_v\)</span> be the degree of vertex <span class="math inline">\(v \in [n]\)</span>, and consider the number of isolated vertices</p><p><span class="math display">\[    Y= \sum_{v=1}^n \mathbf{1}[d_v = 0].\]</span></p><p>With <span class="math inline">\(N=\binom{n}{2}\)</span>, the mean and variance of <span class="math inline">\(Y\)</span> are given by, respectively,</p><p><span class="math display">\[\mu_{n,m}    = n\frac{\binom{N-(n-1)}{m}}{\binom{N}{m}}\]</span></p><p>and</p><p><span class="math display">\[\sigma^2_{n,m} = \mu_{n,m} + n(n-1)\frac{\binom{N-(2n-3)}{m}}{\binom{N}{m}} - \mu_{n,m}^2.\]</span></p></div><p>We construct the coupling as follows:</p><div class="note primary no-icon"><p>Let</p><p><span class="math display">\[\mathcal{E}_n = \bigl\{ \{1,2\}, \dots, \{n-1, n\}\bigr\}.\]</span></p><p>In what follows, for such a <span class="math inline">\(\{v,w\}\)</span> pair, <span class="math inline">\(e_{vw}\)</span> will denote the position of the pair <span class="math inline">\(\{v,w\}\)</span> in the ordered sequence specified by~<span class="math inline">\(\mathcal{E}_n\)</span>, for instance, <span class="math inline">\(e_{1,2}=1\)</span> and <span class="math inline">\(e_{1,3}=2\)</span>.</p><p>Let <span class="math inline">\(\pi\)</span> be a uniformly chosen random permutation of <span class="math inline">\([N]\)</span>, and we will construct a graph <span class="math inline">\(\mathcal{G}(m, \pi)\)</span>, determined by <span class="math inline">\(m\)</span> and <span class="math inline">\(\pi\)</span>, and has the same distribution as <span class="math inline">\(\mathrm{ER} (n, m)\)</span>.</p><p><strong>How to construct the graph</strong> <span class="math inline">\(\mathcal{G}(m,\pi)\)</span>?</p><p>For each <span class="math inline">\(\{v,w\} \subset [n]\)</span> with <span class="math inline">\(v &lt; w\)</span>, connect vertices <span class="math inline">\(v\)</span> and <span class="math inline">\(w\)</span> with an edge if and only if <span class="math inline">\(\pi^{-1} (e_{vw}) \leq m\)</span>, where <span class="math inline">\(e_{vw}\)</span> is the ordered number of the edge <span class="math inline">\(\bigl\{v, w\bigr\}\)</span>.</p><p>Then <span class="math inline">\(\mathcal{G}(m,\pi)\)</span> follows the <span class="math inline">\(\mathrm{ER}(n,m)\)</span> model.</p><p>Let <span class="math inline">\(d_{v}(m, \pi)\)</span> be the degree of vertex <span class="math inline">\(v \in [n]\)</span> in <span class="math inline">\(\mathcal{G}(m, \pi)\)</span>, let</p><p><span class="math display">\[I_v (m, \pi) = \I \bigl[d_{v}(m, \pi) = 0\bigr] \quad  \text{and} \quad Y_{m, \pi} = \sum_{v = n }I_v (m, \pi).  \]</span></p><p>We first describe the algorithm in words: For each given vertex <span class="math inline">\(v ∈ [n]\)</span>, begin with <span class="math inline">\(G(m, \pi)\)</span> and relocate the <span class="math inline">\(d_v(m, \pi)\)</span> edges incident to <span class="math inline">\(v\)</span> uniformly by, starting with <span class="math inline">\(i = 1\)</span> and incrementing when needed, adding <span class="math inline">\(\mathcal{E}_n(\sigma_v(i))\)</span> as a new edge when it connects two vertices, neither of which are incident to <span class="math inline">\(v\)</span> (Step 6), and which are not already connected (Step 7). The counter <span class="math inline">\(k\)</span> records the number of edges successfully relocated, and the set <span class="math inline">\(L^v(m, π, \sigma_v)\)</span> holds their locations, or indices, in <span class="math inline">\(\mathcal E_n\)</span>. At termination, the set <span class="math inline">\(L^v(m, \pi, \sigma_v)\)</span> will have size <span class="math inline">\(d_v(m, \pi)\)</span>.</p></div><div class="note danger no-icon" style="font-family:STKaiti"><p><p>这个用处好像并不是很大，需要再重新考虑考虑。</p><p>或者就是没有找对文章。下午再考虑考虑。</p></p></div><h3 id="一个有用的讲义">一个有用的讲义</h3><ul><li><a href="https://www.win.tue.nl/~rhofstad/SaintFlour_SPoRG.pdf" target="_blank" rel="noopener">https://www.win.tue.nl/~rhofstad/SaintFlour_SPoRG.pdf</a></li></ul><div class="note info"><p>Page 12--13.</p><p><b>1. Generalized random graph conditioned on its degrees</b></p><p>Consider the inhomogeneous random graph models, and specifically, consider the so called <em>generalized random graph</em> which is firstly introduced by Britton, Deijfen and Martin-Lof. In the genralized random graph model, the edge probability of the edge between vertices <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>, is equal to</p><p><span class="math display">\[p_{ij} = \frac{w_i w_j}{\ell_n + w_i w_j}, \tag{p}\label{p}\]</span> where <span class="math inline">\(\mathbf w = (w_i)_{i \in [n]}\)</span> are the vertex weights, and <span class="math inline">\(\ell_n\)</span> is the total weight of all vertices given by <span class="math display">\[\ell_n = \sum_{i \in [n]} w_i.\]</span></p><p>Denote the resulting graph by <span class="math inline">\(\mathrm{GRG}_n(\mathbf w)\)</span>.</p><p><strong>2. Independent and identically distributed weights.</strong> The generalized random graph can be studied both with deterministic weights as well as with independent and identically distributed (i.i.d.) weights. Since we often deal with ratios of the form</p><p><span class="math display">\[\frac{w_iw_j}{\sum_{k \in [n]} w_k},\]</span></p><p>we assume that <span class="math inline">\(\mathbb P[w = 0] = 0\)</span> to avoid situations where all weights are zero</p><p>The great advantage of i.i.d. weights is that the vertices in the resulting graph are, in distribution, the same. More precisely, the vertices are completely exchangeable, like in the Erdos-Renyi random graph <span class="math inline">\(\mathrm{ER}_n(p)\)</span>. Unfortunately, when we take the weights to be i.i.d., then in the resulting graph the edges are no longer independent.</p><p>The generalized random graph with its edge probabilities is rather special. Indeed, when we condition on its degree sequence, then the graph has a uniform distribution over the set of all graphs with the same degree sequence.</p><div class="note success"><p><strong>Theorem.</strong> (GRG conditional on degrees has uniform law).</p><p>The GRG with edge probabilities <span class="math inline">\((p_{ij})_{1 \leq i &lt; j \leq n}\)</span> given by (<span class="math inline">\(\ref{p}\)</span>) conditional on <span class="math inline">\(\{d_i(X) = d_i, \, \forall i \in [n]\}\)</span> is uniform over all graphs with degree sequence <span class="math inline">\((d_i)_{i \in [n]}\)</span>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p><p>This theorem and proof can be found at <a href="https://www.win.tue.nl/~rhofstad/NotesRGCN2013.pdf" target="_blank" rel="noopener">Random Graphs and Complex Networks</a> by Remco van der Hofstad.</p></div></div><h3 id="另一个有用的课程stochastic-processes-on-graphs"><a href="https://web.stanford.edu/~montanar/TEACHING/Stat316/stat316.html" target="_blank" rel="noopener">另一个有用的课程：Stochastic processes on graphs</a></h3><ul><li>By A. Dembo</li></ul><p>There are some topics in this course.</p><ul><li><p><a href="http://web.stanford.edu/~montanar/RESEARCH/FILEPAP/full-version.pdf" target="_blank" rel="noopener">Gibbs Measures and Phase Transitions on Sparse Random Graphs</a>.</p></li><li><p><a href="http://web.stanford.edu/~montanar/OTHER/STATMECH/stflour.pdf" target="_blank" rel="noopener">Statistical Mechanics and Algorithms on Sparse and Random Graphs, by Andrea Montanari</a></p><p>In this note, some classical statistical physics models are discussed.</p></li><li><p><a href="https://arxiv.org/pdf/1211.1094.pdf" target="_blank" rel="noopener">The Sherrington-Kirkpatrick model: an overview</a>.</p></li></ul><section class="footnotes" role="doc-endnotes"><hr /><ol><li id="fn1" role="doc-endnote"><p>R. v. d. Hofstad. Random graphs and complex networks. Volume 1. Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University Press, Cambridge, (2017).<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li></ol></section>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(\def\I{\mathbf{1}}\)&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;睡觉时间：12:00&lt;/li&gt;
&lt;li&gt;起床时间：7:40&lt;/li&gt;
&lt;li&gt;到办公室时间：8:25&lt;/li&gt;
&lt;/ul&gt;
&lt;block
      
    
    </summary>
    
    
      <category term="研究日志" scheme="zhuosongz.github.io/zszhexo.github.io/categories/%E7%A0%94%E7%A9%B6%E6%97%A5%E5%BF%97/"/>
    
    
      <category term="research" scheme="zhuosongz.github.io/zszhexo.github.io/tags/research/"/>
    
  </entry>
  
  <entry>
    <title>研究日志</title>
    <link href="zhuosongz.github.io/zszhexo.github.io/2019/11/05/%E7%A0%94%E7%A9%B6%E6%97%A5%E5%BF%97/"/>
    <id>zhuosongz.github.io/zszhexo.github.io/2019/11/05/研究日志/</id>
    <published>2019-11-05T15:47:42.000Z</published>
    <updated>2019-11-06T01:45:53.799Z</updated>
    
    <content type="html"><![CDATA[<ul><li>昨晚睡觉时间：12:00</li><li>起床时间：7:45</li><li>到办公室时间：8:30</li></ul><p>今天坐公交去办公室，事实证明，会堵车。尤其是刚错过一班车，就要等10分钟。</p><p>早上考虑方老师的问题，我觉得题目有点问题。</p><figure><img src="IMG_2906.JPG" alt="" /><figcaption>方老师的模型似乎有点问题，要重新考虑</figcaption></figure><p>下午考虑Roellin的问题，还是没有太多头绪。</p><p><img src="IMG_2899.JPG" /></p><p>晚上考虑一个多维Berry--Esseen bound的问题。凸集还是很难考虑。称 <span class="math inline">\(f(x):\mathbb{R}^d \mapsto \mathbb{R}\)</span> 是增的： <span class="math display">\[    \langle f(x) - f(y), x - y \rangle \geq 0.\]</span> 希望做到：对于任意的一个<span class="math inline">\(i\)</span>, <span class="math inline">\(f(w)\)</span>是 Stein 方程的解，</p><p><span class="math display">\[\nabla_i f(w)\]</span></p><p>是增的。</p><p><img src="IMG_2907.JPG" /></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;昨晚睡觉时间：12:00&lt;/li&gt;
&lt;li&gt;起床时间：7:45&lt;/li&gt;
&lt;li&gt;到办公室时间：8:30&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;今天坐公交去办公室，事实证明，会堵车。尤其是刚错过一班车，就要等10分钟。&lt;/p&gt;
&lt;p&gt;早上考虑方老师的问题，我觉得题目有点问
      
    
    </summary>
    
    
      <category term="研究日志" scheme="zhuosongz.github.io/zszhexo.github.io/categories/%E7%A0%94%E7%A9%B6%E6%97%A5%E5%BF%97/"/>
    
    
      <category term="convex set" scheme="zhuosongz.github.io/zszhexo.github.io/tags/convex-set/"/>
    
      <category term="Stein&#39;s method" scheme="zhuosongz.github.io/zszhexo.github.io/tags/Stein-s-method/"/>
    
  </entry>
  
  <entry>
    <title>新的开始</title>
    <link href="zhuosongz.github.io/zszhexo.github.io/2019/11/04/%E6%96%B0%E7%9A%84%E5%BC%80%E5%A7%8B/"/>
    <id>zhuosongz.github.io/zszhexo.github.io/2019/11/04/新的开始/</id>
    <published>2019-11-04T15:00:00.000Z</published>
    <updated>2019-11-04T15:54:04.494Z</updated>
    
    <content type="html"><![CDATA[<p>我记得我上次努力，还是十几年前。那个时候还在上高中，心里没有其他的事，不过就是 学习。农村中学的教学宗旨，就是让人勤奋，因为除了勤奋，我们对其他任何一样东西， 都没有办法掌控。家长老师们也都强调：“熬过了这几年，就好了。”一直到好几年后，我 才发现这是一句赤裸裸的谎言。于是天天规律作息：早上五点半起床，六点多跑操，天天 教室、食堂、宿舍，三点一线，晚上十点睡觉。这么过了几年，终于考上了武汉大学。</p><p>上了大学，便不像高中那么勤奋了。而且在大学，我还发现了很多其他更好玩的事情，原 来的自己是那么无知？再加上之前家长老师们的话是那么地深入人心，于是大一时候一度 不知道做什么。大二下的时候，终于良心发现，觉得这么下去，终将颓废，于是便好好上 课认真完成作业，坚持早起。就这样，后来拿到了去香港中文大学留学的机会，这才开始 了研究僧的道路。</p><p>在香港遇到良师益友，都对我影响很大，我在读博士的过程中，也小有收获。可是后来，一种懈怠的心理就上来了，我甚至有段时间觉得科研也不过如此，随便做做，也可以有成就。但是，我忽略了一个大原因，因为有大牛带我，所以很多复杂困难的东西，我并没有面对。后来博士毕业，做了几年博后，这种艰难困苦就更加明显了。我一方面害怕，一方面又拒绝承认是我自己实力不行，所以到了现在，竟然还是那样。我也在不停地寻找原因，似乎也在网上找到了很多道理和建议，但是居然并没有一样能够坚持做下去的。“技不如人？器不如人？” 都不是，而是心不如人，志不如人。</p><p>亡羊补牢，未为晚也。我想从现在开始做出改变。</p><div class="note warning"><p>第一点要做的就是早起，早睡。经过上周的实践，这一点不难做到。之前所以没能成功的原因，不过是自己给自己晚睡晚起找了许多借口：“晚上效率高”，“晚起毁一早上，早起毁一天”云云。雍正皇帝每天早上五点就起来上朝了，皇帝尚且如此，更何况我等无名之辈呢？</div><div class="note warning"><p>第二点，就是要把天天做的东西写下来。可能并不会花太长时间，但是每天坚持写一点自己做的东西，无论成功，无论失败，都是一种记录。曾子曰：“吾日三省吾身”。没有反思，哪里有进步？我并不是完人，又何妨天天给自己挑毛病呢？天天能记下来，长远来看，也是一种成功。</div><div class="note warning"><p>第三点，要给自己制定一些目标和计划。“凡事预则立”。如果没有计划，没有目标，哪里还有早起的动力？哪里还有奋斗的热情？以前种种对自己的纵容，不过就是没有当时高中的激情罢了。</div><div class="note warning"><p>第四点，戒除干扰。微信、视频网站等东西太干扰我的精力了。这些小东西，很像小型毒品，沾得上，拿不掉。但是，以前没有这些东西，不还是好好的吗？昨天看谢益辉的博客，他也说他已经好久不看朋友圈了，至于知乎，他更是对里边的一些“知乎现象”很是反感。是呀，本来就没什么好看的，为什么以前要浪费时间在这些东西上面呢？</div><p>人常说“善始善终”，然而，“善始”者众，而坚持到后来的很少。相信自己能做到的，加油！</p><h4 id="vim-自动给中文换行">vim 自动给中文换行</h4><p>:set formatoptions+=m "允许对multi_byte字符换行（否则默认只能空格或者英文标点，详见set breakat=） :set textwidth=80 "换行的长度 ggVG "选中全文 gq "应用到选中文本</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;我记得我上次努力，还是十几年前。那个时候还在上高中，心里没有其他的事，不过就是 学习。农村中学的教学宗旨，就是让人勤奋，因为除了勤奋，我们对其他任何一样东西， 都没有办法掌控。家长老师们也都强调：“熬过了这几年，就好了。”一直到好几年后，我 才发现这是一句赤裸裸的谎言。于是
      
    
    </summary>
    
    
      <category term="日记" scheme="zhuosongz.github.io/zszhexo.github.io/categories/%E6%97%A5%E8%AE%B0/"/>
    
    
      <category term="life" scheme="zhuosongz.github.io/zszhexo.github.io/tags/life/"/>
    
      <category term="blog" scheme="zhuosongz.github.io/zszhexo.github.io/tags/blog/"/>
    
  </entry>
  
  <entry>
    <title>研究日志</title>
    <link href="zhuosongz.github.io/zszhexo.github.io/2019/11/04/%E7%A0%94%E7%A9%B6%E6%97%A5%E5%BF%97/"/>
    <id>zhuosongz.github.io/zszhexo.github.io/2019/11/04/研究日志/</id>
    <published>2019-11-04T01:00:00.000Z</published>
    <updated>2019-11-04T15:33:18.488Z</updated>
    
    <content type="html"><![CDATA[<ul><li>睡觉时间：2:30</li><li>起床时间：7:30</li><li>到办公室时间：8:30<ul><li>今天坐地铁来学校，然后从地铁站走到办公室，共用时30分钟 (其中走路20分钟)。</li></ul></li><li>午饭: 12:20--13:00</li><li>午睡：13:30--14:00</li></ul><h3 id="morning">Morning</h3><h4 id="paper-reading">Paper reading</h4><p><span class="math inline">\(\def\IR{\mathbb{R}}\def\IP{\mathbb{P}}\def\IE{\mathbb{E}}\)</span></p><ol type="1"><li><p><a href="https://arxiv.org/pdf/1611.02686.pdf" target="_blank" rel="noopener">A paper on weighted bootstrap</a></p><ul><li><p>by Mayya Zhilova;</p></li><li><p>Abstract: We study accuracy of a weighted bootstrap procedure for estimation of quantiles of Euclidean norm of a sum of independent random vectors with zero mean and bounded fourth moment.</p></li><li><p>They consider the non-smooth errors for Balls in the space <span class="math inline">\(\mathbb{R}^d\)</span>.</p></li><li><p>The result is quit sharp, which is of order <span class="math inline">\(n^{-1/2}\)</span>.</p></li></ul></li><li><p><a href="https://projecteuclid-org.libproxy1.nus.edu.sg/download/pdf_1/euclid.aos/1176349666" target="_blank" rel="noopener">One-step and two-step estimators</a></p><ul><li>By Janssen et. al.</li><li>Abstract: A one-step version <span class="math inline">\(M^{(1)}_n\)</span> and a two-step version <span class="math inline">\(M^{(2)}_n\)</span> of a general <span class="math inline">\(M\)</span>-estimator <span class="math inline">\(M_n\)</span> are suggested such that <span class="math inline">\(M_n - M^{(1)}_n = O_p(n^{-1})\)</span> and <span class="math inline">\(M_n - M^{(2)}_n = O_p(n^{-3/2})\)</span> for every <span class="math inline">\(n^{1/2}\)</span>-consistent initial estimator and under some regularity conditions. In the special case of maximum likelihood estimation, this among other yields that the second-order efficiency properties of <span class="math inline">\(M^{(2)}_n\)</span> coincide with those of <span class="math inline">\(M_n\)</span>. An application to the Pitman estimator of location is considered.</li></ul></li><li><p><a href="https://arxiv.org/abs/1205.2947" target="_blank" rel="noopener">A uniform Berry–Esseen theorem on <span class="math inline">\(M\)</span>-estimators for geometrically ergodic Markov chains</a></p><ul><li>By Ledoux and his coauthors</li><li>Abstract: Let <span class="math inline">\(\{X_n\}_{n\ge0}\)</span> be a <span class="math inline">\(V\)</span>-geometrically ergodic Markov chain. Given some real-valued functional <span class="math inline">\(F\)</span>, define <span class="math inline">\(M_n(\alpha):=n^{-1}\sum_{k=1}^nF(\alpha,X_{k-1},X_k)\)</span>, <span class="math inline">\(\alpha\in\mathcal{A}\subset \mathbb {R}\)</span>. Consider an <span class="math inline">\(M\)</span> estimator <span class="math inline">\(\hat{\alpha}_n\)</span>, that is, a measurable function of the observations satisfying <span class="math inline">\(M_n(\hat{\alpha}_n)\leq \min_{\alpha\in\mathcal{A}}M_n(\alpha)+c_n\)</span> with <span class="math inline">\(\{c_n\}_{n\geq1}\)</span> some sequence of real numbers going to zero. Under some standard regularity and moment assumptions, close to those of the i.i.d. case, the estimator <span class="math inline">\(\hat{\alpha}_n\)</span> satisfies a Berry--Esseen theorem uniformly with respect to the underlying probability distribution of the Markov chain.</li><li>Therefore, this can should be carefully read.</li><li>Markov chain and <span class="math inline">\(M\)</span> estimators.</li></ul></li></ol><h4 id="berry--esseen-bound-for-m-estimators.">Berry--Esseen bound for <span class="math inline">\(M\)</span> estimators.</h4><ol type="1"><li><p><a href="https://www-jstor-org.libproxy1.nus.edu.sg/stable/pdf/4616471.pdf?refreqid=excelsior%3A3d89efc93c85b5722673ba093b37c3a9" target="_blank" rel="noopener">A Berry-Esséen Bound for M-Estimators, 1997</a></p><ul><li>By V. Bentkus, M. Bloznelis and F. Götze.</li><li>Potential problems:<ul><li>Convexity: Convexity There exist <span class="math inline">\(\delta\)</span> &gt; 0 and B &gt; 0 such that <span class="math display">\[      \mathbb{P} \bigl[ Q_N(t) \text{ is convex on } (t_0 - \delta , t_0 + \delta) \bigr] \geq 1 - B N^{-1/2}.  \]</span></li><li>Can we weaken this condition to <span class="math inline">\(\mathbb{E} Q_N\)</span>?</li><li><span class="math inline">\(\IR\)</span>.</li><li>What they considered is the one-dimensional case: <span class="math display">\[       \Delta_N := \sup_{ u \in \IR } |\IP[N^{1/2} (t_N - t_0)/b &lt; u] -\Phi(u) | \leq C N^{-1/2},  \]</span> provided that <span class="math display">\[      N / \log N \geq \text{some constant}.  \]</span></li></ul></li></ul></li><li><p><a href="https://eml.berkeley.edu/wp/mcfadden1007.pdf" target="_blank" rel="noopener">Maximal Uniform Convergence Rates in Parametric Estimation Problems</a></p></li><li><p><a href="http://www.stats.ox.ac.uk/~evans/Part%20III%20Essay.pdf" target="_blank" rel="noopener">A Thesis on convergence rate of MLE</a></p></li><li><p><a href="https://www.stat.washington.edu/jaw/RESEARCH/TALKS/uw.pdf" target="_blank" rel="noopener">A slides on convergence rate of MLE and empirical process theory</a></p></li></ol><h3 id="afternoon">Afternoon</h3><h4 id="graph-problems">1. Graph problems</h4><p>Consider the following configuration model:</p><p>Let $G_n $ be a random graph with <span class="math inline">\(n\)</span> vertices, and for each vertex <span class="math inline">\(i\)</span>, let <span class="math inline">\(d_i\)</span> be its degree. We want to prove <span class="math inline">\(G_n \to h\)</span>, where <span class="math inline">\(h (x, y) = f(x) f(y)\)</span>, and <span class="math inline">\(f(x)\)</span> is the ''degree'' of <span class="math inline">\(x\)</span>. Construct the graph sequence as follows: let <span class="math inline">\(G_n(t)\)</span> be the graph at time <span class="math inline">\(t\)</span>, and generate <span class="math inline">\(G_n(t + 1)\)</span> by randomly picking two vertices <span class="math inline">\((i_1, i_2)\)</span> adjoint to <span class="math inline">\(j\)</span>, and then switch the types of <span class="math inline">\((i_1, j)\)</span> and <span class="math inline">\((i_2, j)\)</span> or delete <span class="math inline">\((i_1,j)\)</span> anyway.</p><ul><li>If we only switch the types of <span class="math inline">\((i_1, j)\)</span> and <span class="math inline">\((i_2, j)\)</span>, then it follows that the total number of the edges do not change. Let <span class="math inline">\((d_{1,t}, \dots, d_{n, t})\)</span> be the degree sequence at time <span class="math inline">\(t\)</span>, we guess that the distribution of <span class="math inline">\((d_{1,t} , \dots, d_{n,t})\)</span> does not change over time <span class="math inline">\(t\)</span>.</li></ul><blockquote><p>Proof:</p></blockquote><h3 id="cheatsheets">Cheatsheets:</h3><ul><li><a href="https://startupsventurecapital.com/essential-cheat-sheets-for-machine-learning-and-deep-learning-researchers-efb6a8ebd2e5" target="_blank" rel="noopener">Essential Cheat Sheets for Machine Learning and Deep Learning Engineers</a><ul><li>some python and R techniques.</li></ul></li></ul><h3 id="gmc">GMC</h3><blockquote><p>By Adam</p></blockquote><p>Let <span class="math inline">\(M_{\gamma} (A) = \int_{A} \exp \bigl( \gamma X(v) - \frac{\gamma^2}{2} \IE (X(x)^2)\bigr)\)</span> where <span class="math inline">\(\gamma^2 &lt; 2 d\)</span> and <span class="math inline">\(X(x)\)</span> is a centered Gaussian field with covariance</p><p><span class="math display">\[K(x, y) = \log \biggl(\frac{1}{|x - y|}\biggr) + g(x, y). \]</span></p><p>It has been shown that <span class="math inline">\(\forall c &gt; 0\)</span> and <span class="math inline">\(p \in (-\infty, 2d/\gamma^2)\)</span>, then</p><p><span class="math display">\[\IE \bigl\{ M_\gamma (B(0, c))^p\bigr\} &lt; \infty, \]</span></p><p>and suggested that</p><p><span class="math display">\[\IP \Bigl[ M_{\gamma} ( B(0, c)) &gt; t\Bigr] \approx c t^{-2d^2/\gamma^2}.\]</span></p><p>If <span class="math inline">\(d = 1\)</span>, <span class="math inline">\(g = 0\)</span>, Boral and Sin showed that there exists <span class="math inline">\(c &gt; 0\)</span> such that</p><p><span class="math display">\[\lim_{t \to \infty} t^{2/\gamma^2} \IP \bigl[ M_{\gamma} (A) &gt; t\bigr] = c, \]</span></p><p>where <span class="math inline">\(A \subset \IR\)</span> is an interval.</p><h4 id="theorem-1.-rhodes-and-vargas-2019">Theorem 1. (<strong>Rhodes and Vargas (2019)</strong>)</h4><p>When <span class="math inline">\(d = 2\)</span>, <span class="math inline">\(g \equiv 0\)</span> on a <span class="math inline">\(D\)</span>-disk for <span class="math inline">\(\delta &gt; 0\)</span> sufficiently small, <span class="math inline">\(O \subset D\)</span> is open with <span class="math inline">\(C^1\)</span> boundary,</p><p><span class="math display">\[\IP \Bigl[ M_{\gamma} (O) &gt; t\Bigr] = c_\gamma \lvert O \rvert t^{-4/\delta^2} + \mathrm{o} (t^{-6/\gamma^2 - \delta }), \]</span></p><p>where <span class="math inline">\(c_{\gamma} = (t/\gamma^2 - 1) \bar{R} (\gamma)\)</span>.</p><ul><li>generalize for other dimension?</li></ul><h5 id="proof."><strong>Proof.</strong></h5><p><strong>Step 1.</strong> Localization trick:</p><p><span class="math display">\[\begin{aligned}    \IP \Bigl[ M_{\gamma}(O) &gt; t\Bigr] &amp; = \IE \biggl\{ \frac{M_\gamma(O)}{M_{\gamma}(O)} \mathbf{1} \bigl( M_{\gamma} (O) &gt;t\bigr)\biggr\}\\&amp;= \int_{ O }^{  } \IE \biggl\{ e^{\gamma X(v) - \frac{\gamma^2}{2} \IE (X(v)^2)}\frac{1}{M_{\gamma}(O)} \mathbf{1} \bigl( M_{\gamma} (O) &gt;t\bigr) \biggr\} d v\\&amp;= \int_{ O }^{  } \IE \biggl\{\frac{1}{M_{\gamma}(O)} \mathbf{1} \bigl( M_{\gamma} (v, O) &gt;t\bigr) \biggr\} d v, \end{aligned}\tag{1}\]</span></p><p>where</p><p><span class="math display">\[M_{\gamma} (v, O) = \int_{O} \frac{1}{ \lvert z - v \rvert^{\gamma^2}} M_{\gamma} (d z).\]</span></p><p><strong>Step 2.</strong> As <span class="math inline">\(r &gt; 0\)</span>,</p><p><span class="math display">\[\begin{aligned}    (1) &amp; \to \IE \biggl\{ \frac{1}{M_{\gamma} (v, B_r(v))} \mathbf{1} \bigl(M_{\gamma} (v, B_r(v))    &gt; t \bigr) \biggr\}\\    &amp; = r^{ 2 - \gamma^2 } \exp \Bigl\{ \gamma N_{v, r} - \frac{\gamma^2}{2} \IE N_{v, r} \Bigr\}    \underbrace{\int_{0}^{\infty} \exp \bigl[ \gamma \bigl( B_s - (2/\gamma - \gamma/2) s\bigr)    \bigr]}_{:= \bar R (\gamma)}.\end{aligned}\]</span></p><p><strong>End of the proof</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;睡觉时间：2:30&lt;/li&gt;
&lt;li&gt;起床时间：7:30&lt;/li&gt;
&lt;li&gt;到办公室时间：8:30
&lt;ul&gt;
&lt;li&gt;今天坐地铁来学校，然后从地铁站走到办公室，共用时30分钟 (其中走路20分钟)。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;午饭: 12:20--
      
    
    </summary>
    
    
      <category term="研究日志" scheme="zhuosongz.github.io/zszhexo.github.io/categories/%E7%A0%94%E7%A9%B6%E6%97%A5%E5%BF%97/"/>
    
    
      <category term="review" scheme="zhuosongz.github.io/zszhexo.github.io/tags/review/"/>
    
      <category term="Bootstrap" scheme="zhuosongz.github.io/zszhexo.github.io/tags/Bootstrap/"/>
    
      <category term="Statistical application" scheme="zhuosongz.github.io/zszhexo.github.io/tags/Statistical-application/"/>
    
      <category term="MLE" scheme="zhuosongz.github.io/zszhexo.github.io/tags/MLE/"/>
    
      <category term="M estimator" scheme="zhuosongz.github.io/zszhexo.github.io/tags/M-estimator/"/>
    
  </entry>
  
  <entry>
    <title>19-11-04</title>
    <link href="zhuosongz.github.io/zszhexo.github.io/2019/11/03/19-11-04/"/>
    <id>zhuosongz.github.io/zszhexo.github.io/2019/11/03/19-11-04/</id>
    <published>2019-11-03T15:09:54.000Z</published>
    <updated>2019-11-04T15:34:33.599Z</updated>
    
    <content type="html"><![CDATA[<p>今天周日，搭建了一下个人网站。</p><p>晚上2点睡觉。</p><p>以后每天都要做更新，保持好的一种状态。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;今天周日，搭建了一下个人网站。&lt;/p&gt;
&lt;p&gt;晚上2点睡觉。&lt;/p&gt;
&lt;p&gt;以后每天都要做更新，保持好的一种状态。&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="日记" scheme="zhuosongz.github.io/zszhexo.github.io/categories/%E6%97%A5%E8%AE%B0/"/>
    
    
      <category term="life" scheme="zhuosongz.github.io/zszhexo.github.io/tags/life/"/>
    
  </entry>
  
</feed>
